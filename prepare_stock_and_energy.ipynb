{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "# Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open 1 None continuous\n",
      "High 1 None continuous\n",
      "Low 1 None continuous\n",
      "Close 1 None continuous\n",
      "Adj_Close 1 None continuous\n",
      "Volume 1 None continuous\n",
      "6 3661\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from stock_energy.missingprocessor import Processor\n",
    "import pickle\n",
    "\n",
    "data_path = \"./TimeGAN/data\"\n",
    "loc = \"stock\"\n",
    "seq_len = 24\n",
    "df = pd.read_csv('{}/{}_data.csv'.format(data_path,loc), sep = \",\") # [n_data*n_seq, n_feature]\n",
    "types = [\"continuous\" for i in range(len(df.columns))] # [n_feature]\n",
    "\n",
    "P = Processor(types)\n",
    "# Flip the data to make chronological data\n",
    "ori_data = P.fit_transform(df)\n",
    "ori_data = ori_data[::-1]\n",
    "\n",
    "temp_data = [ori_data[i:i + seq_len] for i in range(0, len(ori_data) - seq_len)]  # [(n_data-n_seq) * [n_seq * n_feature]]]   \n",
    "\n",
    "from fastNLP import DataSet\n",
    "dataset = DataSet({\"seq_len\": [seq_len] * len(temp_data), \"dyn\": temp_data, \"sta\":[0]*len(temp_data)})\n",
    "dic = {\n",
    "    \"train_set\": dataset,\n",
    "    \"dynamic_processor\": P,\n",
    "    \"static_processor\": Processor([])\n",
    "}\n",
    "print(P.dim, len(temp_data))\n",
    "from utils.general import make_sure_path_exists\n",
    "make_sure_path_exists(\"./data\")\n",
    "with open(\"./data/{}.pkl\".format(loc), \"wb\") as f:\n",
    "    pickle.dump(dic, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prepare sine normal from COSCI-GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1638400, 2)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.shape\n",
    "\n",
    "ori_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 None continuous\n",
      "1 1 None continuous\n",
      "2 2048\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from stock_energy.missingprocessor import Processor\n",
    "import pickle\n",
    "\n",
    "data_path = \"../COSCI-GAN/Dataset/\"\n",
    "loc = \"data_frame_sine_normal.pkl\"\n",
    "seq_len = 800\n",
    "\n",
    "\n",
    "\n",
    "with open(data_path+loc, \"rb\") as f:\n",
    "    data = pickle.load(f).iloc[:, :-1].values # [n_samples, seq_len * n_features]\n",
    "data2 = np.stack([data[:,:seq_len].flatten(), data[:,seq_len:].flatten()], axis=1) # [n_samples* seq_len , n_features]\n",
    "\n",
    "# DEBUG\n",
    "# print(data.shape)\n",
    "# print(data[0,:20])\n",
    "# print(data[0,800:820])\n",
    "\n",
    "# data2.shape\n",
    "# data2[:20,:]\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data2)\n",
    "types = [\"continuous\" for i in range(len(df.columns))] # [n_feature]\n",
    "P = Processor(types)\n",
    "\n",
    "# Flip the data to make chronological data\n",
    "ori_data = P.fit_transform(df)\n",
    "# ori_data = ori_data[::-1]\n",
    "# print(ori_data[:5,:])\n",
    "# temp_data = [ori_data[i:i + seq_len] for i in range(0, len(ori_data) - seq_len)]  \n",
    "\n",
    "\n",
    "temp_data = [ori_data[i:i + seq_len] for i in range(0, len(ori_data),seq_len)] # [(n_data-n_seq) * [n_seq * n_feature]]]   \n",
    "\n",
    "# DEBUG\n",
    "# a = [i for i in range(0, len(ori_data),seq_len)]\n",
    "# len(ori_data), a[:5], a[-5:]\n",
    "# len(temp_data), temp_data[0].shape\n",
    "# temp_data[0][:5]\n",
    "\n",
    "\n",
    "from fastNLP import DataSet\n",
    "dataset = DataSet({\"seq_len\": [seq_len] * len(temp_data), \"dyn\": temp_data, \"sta\":[0]*len(temp_data)})\n",
    "dic = {\n",
    "    \"train_set\": dataset,\n",
    "    \"dynamic_processor\": P,\n",
    "    \"static_processor\": Processor([])\n",
    "}\n",
    "print(P.dim, len(temp_data))\n",
    "from utils.general import make_sure_path_exists\n",
    "make_sure_path_exists(\"./data\")\n",
    "with open(\"./data/{}\".format(loc), \"wb\") as f:\n",
    "    pickle.dump(dic, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
